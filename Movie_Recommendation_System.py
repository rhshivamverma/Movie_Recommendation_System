# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XIYuLGsJ0FIf0J-t3eEDPZLM1e6KgscO
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.metrics.pairwise import linear_kernel, cosine_similarity
import matplotlib.pyplot as plt
from ast import literal_eval

movies = pd.read_csv('/content/tmdb_5000_movies.csv')
credits = pd.read_csv('/content/tmdb_5000_credits.csv')
credits.columns = ['id','title','cast','crew']
movies = movies.merge(credits, on='id')

c = movies['vote_average'].mean()
m = movies['vote_count'].quantile(0.9)
movies_list = movies.loc[movies['vote_count'] >= m].copy()

def weighted_rating(x, m=m, c=c):
    v = x['vote_count']
    r = x['vote_average']
    return (v/(v+m)*r) + (m/(m+v)*c)

movies_list['score'] = movies_list.apply(weighted_rating, axis=1)
top_10_movies = movies_list.sort_values('score', ascending=False).head(10)

popular = movies.sort_values('popularity', ascending=False)
plt.barh(popular['title_x'].head(10), popular['popularity'].head(10))


budget = movies.sort_values('budget', ascending=False)
plt.barh(budget['title_x'].head(10), budget['budget'].head(10))

tfdif = TfidfVectorizer(stop_words='english')
movies['overview'] = movies['overview'].fillna('')
tfdif_matrix = tfdif.fit_transform(movies['overview'])
cosine_sim = linear_kernel(tfdif_matrix, tfdif_matrix)

indices = pd.Series(movies.index, index=movies['title_x']).drop_duplicates()

def get_recommendations(title, cosine_sim=cosine_sim):
    idx = indices[title]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:11]
    movie_indices = [i[0] for i in sim_scores]
    return movies['title_x'].iloc[movie_indices]

from ast import literal_eval

def safe_literal_eval(x):
    try:
        return literal_eval(x)
    except (ValueError, SyntaxError):
        return []  # Return empty list for malformed entries

features = ['cast', 'crew', 'genres', 'keywords']
for feature in features:
    movies[feature] = movies[feature].apply(safe_literal_eval)

def get_director(x):
    for i in x:
        if i.get('job') == 'Director':
            return i.get('name')
    return np.nan

def get_list(x):
    if isinstance(x, list):
        names = [i.get('name') for i in x if isinstance(i, dict)]
        return names[:3]
    return []

movies['director'] = movies['crew'].apply(get_director)

for feature in ['cast', 'keywords', 'genres']:
    movies[feature] = movies[feature].apply(get_list)

def clean_data(x):
    if isinstance(x, list):
        return [str.lower(i.replace(" ", "")) for i in x]
    else:
        return str.lower(x.replace(" ", "")) if isinstance(x, str) else ''

for feature in ['cast','keywords','director','genres']:
    movies[feature] = movies[feature].apply(clean_data)

def create_soup(x):
    return ' '.join(x['keywords']) + ' ' + ' '.join(x['cast']) + ' ' + x['director'] + ' ' + ' '.join(x['genres'])

movies['soup'] = movies.apply(create_soup, axis=1)

count = CountVectorizer(stop_words='english')
count_matrix = count.fit_transform(movies['soup'])
cosine_sim2 = cosine_similarity(count_matrix, count_matrix)

import difflib

def find_closest_title(title, titles):
    matches = difflib.get_close_matches(title, titles, n=1, cutoff=0.6)
    return matches[0] if matches else None

input_title = "Toy Story"
matched_title = find_closest_title(input_title, movies['title_x'].dropna().unique())

if matched_title:
    print(f"Best match for '{input_title}': {matched_title}")
    print(get_recommendations(matched_title, cosine_sim2))
else:
    print(f"No close match found for '{input_title}'")











